{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TS_datawindow import DataWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12285, 5) (3510, 5) (1756, 5)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"C:/Users/campus3S031/Desktop/iMBank/iM_DiGital_Banker_academy/ML_TS/data/\"\n",
    "\n",
    "train_df = pd.read_csv(DATA_PATH + 'train.csv', index_col=0)\n",
    "val_df = pd.read_csv(DATA_PATH + 'val.csv', index_col=0)\n",
    "test_df = pd.read_csv(DATA_PATH + 'test.csv', index_col=0)\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 클래스는 같은 폴더 안에 있는 TS_datawindow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 LSTM 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complile_and_fit (model, window, patience = 3, max_epochs = 50):\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', # 무엇을 볼 것인가?\n",
    "                                   patience = patience,\n",
    "                                   mode = 'min')\n",
    "    \n",
    "    model.compile(loss = MeanSquaredError(),\n",
    "                  optimizer = Adam(),\n",
    "                  metrics = [MeanAbsoluteError()])\n",
    "    \n",
    "    history = model.fit(window.train,\n",
    "                        epochs = max_epochs,\n",
    "                        validiation_data = window.val,\n",
    "                        callbacks = [early_stopping])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp': 0, 'clouds_all': 1, 'traffic_volume': 2, 'day_sin': 3, 'day_cos': 4}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_indices = {name: i for i , name in enumerate(train_df.columns)}\n",
    "column_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWindow():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df=train_df, val_df=val_df, test_df=test_df,\n",
    "                 label_columns=None):\n",
    "\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "\n",
    "        self.total_window_size = input_width + shift\n",
    "\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "\n",
    "    def split_to_inputs_labels(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1\n",
    "            )\n",
    "        inputs.set_shape([None, self.input_width, None])\n",
    "        labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "        return inputs, labels\n",
    "\n",
    "    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n",
    "        inputs, labels = self.sample_batch\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plot_col_index = self.column_indices[plot_col]\n",
    "        max_n = min(max_subplots, len(inputs))\n",
    "\n",
    "        for n in range(max_n):\n",
    "            plt.subplot(3, 1, n+1)\n",
    "            plt.ylabel(f'{plot_col} [scaled]')\n",
    "            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "                     label='Inputs', marker='.', zorder=-10)\n",
    "\n",
    "            if self.label_columns:\n",
    "              label_col_index = self.label_columns_indices.get(plot_col, None)\n",
    "            else:\n",
    "              label_col_index = plot_col_index\n",
    "\n",
    "            if label_col_index is None:\n",
    "              continue\n",
    "\n",
    "            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n",
    "            if model is not None:\n",
    "              predictions = model(inputs)\n",
    "              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                          marker='X', edgecolors='k', label='Predictions',\n",
    "                          c='red', s=64)\n",
    "\n",
    "            if n == 0:\n",
    "              plt.legend()\n",
    "\n",
    "        plt.xlabel('Time (h)')\n",
    "\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32\n",
    "        )\n",
    "\n",
    "        ds = ds.map(self.split_to_inputs_labels)\n",
    "        return ds\n",
    "\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)\n",
    "\n",
    "    @property\n",
    "    def sample_batch(self):\n",
    "        result = getattr(self, '_sample_batch', None)\n",
    "        if result is None:\n",
    "            result = next(iter(self.train))\n",
    "            self._sample_batch = result\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단일 단계 LSTM 모델\n",
    "- 24시간의 데이터 입력으로 사용 후 다음 시간 단계 예측\n",
    "- 모델을 훈련할 데이터 윈도우 만들기\n",
    "- 24시간의 데이터를 입력으로 사용하는 넓은 윈도우\n",
    "- 도식화 위해 label_width도 24로 설정\n",
    "- 예측값을 24개의 시간 단계에 걸쳐 실제값과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window = DataWindow(input_width = 1, label_width = 1, shift = 1, label_columns = ['traffic_volume'])\n",
    "wide_window = DataWindow(input_width = 24, label_width = 24, shift = 1, label_columns = ['traffic_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도식화를 위해 더 넓은 윈도우를 정의, 모델의 많은 예측 시각화\n",
    "- 그렇지 않으면 하나의 입력 데이터 요소와 하나의 출력 예측만 시각화\n",
    "- 즉 wide_window를 쓴다는 뜻이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_val = [0.083, 0.068, 0.033]\n",
    "mae_test = [0.081, 0.068, 0.029]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_mpdel = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
