{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai langchain langchain-community langchain-core langchain_openai langchain-experimental --q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동적 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "API Key loaded successfully\n",
      "API Key: sk-proj-...yTUA\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def load_env_from_project_root():\n",
    "    \"\"\"\n",
    "    현재 실행 중인 스크립트(LLM_basic.ipynb)에서\n",
    "    step10_LLM 디렉토리의 .env 파일을 로드\n",
    "    \"\"\"\n",
    "    # 현재 파일 위치\n",
    "    current_path = Path.cwd()\n",
    "    \n",
    "    # step10_LLM 디렉토리로 이동 (../../)\n",
    "    project_root = current_path.parent.parent\n",
    "    \n",
    "    # .env 파일 경로\n",
    "    env_path = project_root / '.env'\n",
    "    \n",
    "    # .env 파일이 존재하는지 확인\n",
    "    if env_path.exists():\n",
    "        load_dotenv(env_path)\n",
    "        print(f\"Loaded .env from: {env_path}\")\n",
    "        return True\n",
    "    else:\n",
    "        raise FileNotFoundError(f\".env file not found at: {env_path}\")\n",
    "\n",
    "# 실행\n",
    "try:\n",
    "    load_env_from_project_root()\n",
    "    \n",
    "    # 환경 변수 사용\n",
    "    api_key = os.getenv('OPENAI_API_KEY')\n",
    "    if api_key:\n",
    "        print(\"API Key loaded successfully\")\n",
    "        # API 키 마스킹하여 출력\n",
    "        masked_key = f\"{api_key[:8]}...{api_key[-4:]}\"\n",
    "        print(f\"API Key: {masked_key}\")\n",
    "    else:\n",
    "        print(\"API Key not found in .env file\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading .env file: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 아래 코드 설명\n",
    "- 프롬프트 템플릿을 만들어서 질문을 입력받고 답변을 생성하는 체인을 구성합니다.\n",
    "- 체인은 다음과 같이 구성됩니다:\n",
    "  1. PromptTemplate: 질문을 받아 포맷팅\n",
    "  2. ChatOpenAI: GPT 모델을 통한 답변 생성 \n",
    "  3. StrOutputParser: 출력을 문자열로 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016년 올림픽은 브라질의 리우데자네이루에서 열렸습니다. 이제 단계별로 리우데자네이루의 인구에 대해 알아보겠습니다.\n",
      "\n",
      "1. **올림픽 개최 도시 확인**: 2016년 여름 올림픽은 리우데자네이루에서 진행되었습니다.\n",
      "  \n",
      "2. **리우데자네이루의 수도 역할 확인**: 리우데자네이루는 브라질의 수도가 아닙니다. 브라질의 현재 수도는 브라질리아(Brasília)입니다. 하지만 리우데자네이루는 과거에 브라질의 수도였던 도시입니다.\n",
      "\n",
      "3. **인구 조사**: 리우데자네이루의 인구는 2020년 기준으로 약 670만 명 정도입니다. 최근 인구 통계나 다른 지표에 따라 수치는 조금 달라질 수 있습니다.\n",
      "\n",
      "결론적으로, 2016년 올림픽이 열린 리우데자네이루는 현재 약 670만 명의 인구를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question} 단계별로 생각해봅시다.\n",
    "Answer: \"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "chain = prompt | ChatOpenAI(model_name=\"gpt-4o-mini\") | StrOutputParser()\n",
    "question = \"2016년 올림픽이 열린 국가의 수도는 인구가 얼마인가요?\"\n",
    "print(chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 에이전트와 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia numexpr --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\venv\\Lib\\site-packages\\langsmith\\client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe first step is to find out which country won the 2023 Rugby World Cup. Once I have that information, I will then need to find the population of that country to calculate the square root of its population. \n",
      "\n",
      "Action: wikipedia  \n",
      "Action Input: 2023 Rugby World Cup winner  \n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: 2023 Rugby World Cup\n",
      "Summary: The 2023 Rugby World Cup (French: Coupe du monde de rugby 2023) was the  tenth men's Rugby World Cup, the quadrennial world championship for national rugby union teams. It took place in France from 8 September to 28 October 2023 in nine venues across the country. The opening game and final took place at the Stade de France, north of Paris. The tournament was held in the bicentenary year of the purported invention of the sport by William Webb Ellis.\n",
      "The tournament was scheduled to last six weeks, but in February 2021 World Rugby added a week to provide additional rest days for player welfare. This meant that teams had a minimum of five days' rest for all matches. It was the fourth time France has hosted the Rugby World Cup, having previously done so in 2007 and co-hosted the 1991 Rugby World Cup and 1999 Rugby World Cup with England, Ireland, Scotland and Wales. This was the last tournament to feature 20 teams taking part, as the tournament will be expanded to include 24 teams in 2027.\n",
      "The defending champions were South Africa, who defeated England in the 2019 Rugby World Cup final. South Africa retained their title by defeating New Zealand in the final. In doing so, they became the first team to win the tournament four times and they remain the only team to ever win the World Cup after losing a match in the pool stage, as well as the first team to win successive World Cup titles away from home. The result also marked their second victory over New Zealand in a final (winning 15–12 a.e.t. in 1995), and also their second victory in a final on French soil (defeating England 15–6 in 2007). As well as winning the World Cup after losing a pool game for the second consecutive time, they won each of their knockout games against France, England and New Zealand by a margin of 1 point.\n",
      "Chile made their first appearance in the tournament. Portugal returned for their second appearance, 16 years after their debut in 2007, also in France.\n",
      "\n",
      "Page: Rugby World Cup\n",
      "Summary: The Men's Rugby World Cup is a rugby union tournament contested every four years between the top international teams, the winners of which are recognised as the World champions of the sport.\n",
      "The tournament is administered by World Rugby, the sport's international governing body. The winners are awarded the Webb Ellis Cup, named after William Webb Ellis who, according to a popular legend, invented rugby by picking up the ball during a football game and running with it.\n",
      "The tournament was first held in 1987 and was co-hosted by New Zealand and Australia. Four countries have won the trophy; South Africa four times, New Zealand three times, Australia twice, and England once. South Africa is the current champion, having defeated  New Zealand in the final of the 2023 tournament.\n",
      "Sixteen teams participated in the tournament from 1987 until 1995; in 1999, the tournament expanded to twenty teams. Japan hosted the 2019 Rugby World Cup and France hosted the 2023 Rugby World Cup. The tournament will expand again to twenty-four teams when it is held in Australia in 2027.\n",
      "Starting in 2021, the women's equivalent tournament was officially renamed the Rugby World Cup to promote equality with the men's tournament. However, the 2021 event was the only one to use this naming convention as at the end of the 2023 World Cup, World Rugby announced that all preceding tournaments would include the words \"Men's\" or \"Women's\" in their titles. The first event to use this convention will be the 2025 Women's Rugby World Cup, while the 2027 Men's Rugby World Cup will be the first to include \"Men's\" in its title.\n",
      "\n",
      "Page: 2027 Men's Rugby World Cup\n",
      "Summary: The 2027 Men's Rugby World Cup is scheduled to be the 11th edition of the Rugby World Cup, the quadrennial world championship for men's rugby union teams. It is scheduled to take place in Australia from 1 October to 13 November 2027. It will be the first tournament to be branded as the Men's Rugby World Cup, a change that\u001b[0m\u001b[32;1m\u001b[1;3mI have found that South Africa won the 2023 Rugby World Cup by defeating New Zealand in the final. The next step is to find the population of South Africa to calculate the square root of that population.\n",
      "\n",
      "Action: wikipedia  \n",
      "Action Input: Population of South Africa 2023  \n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Demographics of South Africa\n",
      "Summary: According to the 2022 census, the population of South Africa is about 62 million people of diverse origins, cultures, languages, and religions. With a majority being Black Africans. The South African National Census of 2022 was the most recent census held; the next will be in 2032.\n",
      "In 2011, Statistics South Africa counted 2.1 million foreigners in total. Reports suggest that is an underestimation. The real figure may be as high as five million, including some three million Zimbabweans.\n",
      "\n",
      "Page: List of South African provinces by population\n",
      "Summary: Since the election of 27 April 1994, South Africa has been divided into nine provinces. They vary widely in population, from the mostly-urban Gauteng, which contains over 20% of the national population, to the mostly-desert Northern Cape, which contains less than 3%. The following table shows the provincial populations according to the 2011 National Census, the 2016 Community Survey, and the most recent 2022 Census.\n",
      "\n",
      "Page: South Africa\n",
      "Summary: South Africa, officially the Republic of South Africa (RSA), is the southernmost country in Africa. Its nine provinces are bounded to the south by 2,798 kilometres (1,739 miles) of coastline that stretches along the South Atlantic and Indian Ocean; to the north by the neighbouring countries of Namibia, Botswana, and Zimbabwe; to the east and northeast by Mozambique and Eswatini; and it encloses Lesotho. Covering an area of 1,221,037 square kilometres (471,445 square miles), the country has  over 62 million people. Pretoria is the administrative capital, while Cape Town, as the seat of Parliament, is the legislative capital. Bloemfontein has traditionally been regarded as the judicial capital. The largest and most populous city is Johannesburg, followed by Cape Town and the busiest port city in sub-Saharan Africa, Durban.\n",
      "Archaeological findings suggest that various hominid species existed in South Africa about 2.5 million years ago, and modern humans inhabited the region over 100,000 years ago. The first known people were the indigenous Khoisan, and Bantu-speaking peoples who expanded from West and Central Africa later settled in the region 2,000 to 1,000 years ago. In the north, the Kingdom of Mapungubwe formed in the 13th century. In 1652, the Dutch established the first European settlement at Table Bay, and in 1795 and 1806, the British occupied it. The Mfecane, a period of significant upheaval, led to the formation of various African kingdoms, including the Zulu Kingdom. The region was further colonised, and diamonds and gold were discovered, bringing a shift towards industrialisation and urbanisation. The Union of South Africa was created in 1910 out of the former Cape, Natal, Transvaal, and Orange River colonies, becoming a republic in 1961. Though a system of multi-racial franchise had existed in the Cape, it was gradually eroded, and the vast majority of Black South Africans were not enfranchised until 1994.\n",
      "The National Party imposed apartheid in 1948, institutionalising previous racial segregation. After a largely non-violent struggle by the African National Congress and other anti-apartheid activists both inside and outside the country, the repeal of discriminatory laws began in the mid-1980s. Universal elections took place in 1994, following which all racial groups have held political representation in the country's liberal democracy, which comprises a parliamentary republic and nine provinces.\n",
      "South Africa is a multi-ethnic society encompassing a variety of cultures, languages, and religions; it is often called the \"rainbow nation\" to describe its multicultural diversity, especially in the wake of apartheid. Recognised as a middle power in international affairs, South Africa maintains significant regional influence and is a member of BRICS+, the African Union, SADC, SACU, the Commonwealth of Nations, and the G20. A developing, newly industrialised country, South Africa has the largest eco\u001b[0m\u001b[32;1m\u001b[1;3mI have found that the estimated population of South Africa is about 62 million people. Now I will calculate the square root of this population figure.\n",
      "\n",
      "Action: Calculator  \n",
      "Action Input: 62_000_000  \n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 62000000\u001b[0m\u001b[32;1m\u001b[1;3mTo find the square root of the population, I need to calculate it once more.\n",
      "\n",
      "Action: Calculator  \n",
      "Action Input: 62_000_000 ** 0.5  \n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mAnswer: 7874.007874011811\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: 약 7874.01\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '2023 럭비 월드컵에서 우승한 나라의 인구의 제곱근은 얼마인가요?', 'output': '약 7874.01'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "\n",
    "from langchain_community.agent_toolkits.load_tools import load_tools\n",
    "from langchain import hub\n",
    "\n",
    "load_env_from_project_root()\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    prompt=hub.pull(\"hwchase17/react\"),\n",
    ")\n",
    "\n",
    "# 복잡한 문제에 대한 추론 능력을 보여주고 있음\n",
    "question = \"2023 럭비 월드컵에서 우승한 나라의 인구의 제곱근은 얼마인가요?\"\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랭스미스 : 메모리 기능 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph --q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "안녕하세요. 저는 홍길동입니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "안녕하세요, 홍길동님! 저희 상점에 오신 것을 환영합니다. 어떤 도움을 드릴 수 있을까요? 필요하신 상품이나 정보가 있으시면 말씀해 주세요.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "제 이름을 기억하나요?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "네, 홍길동님이라고 말씀하셨습니다. 고객님의 이름을 기억하는 것은 중요하다고 생각합니다! 더 궁금하신 점이나 필요하신 것이 있으면 언제든지 말씀해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "import uuid\n",
    "\n",
    "load_env_from_project_root()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# 상태 그래프 정의\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "# llm 호출 함수 정의\n",
    "def call_llm(state: MessagesState):\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# 그래프에 llm 추가\n",
    "workflow.add_edge(START, \"llm\")\n",
    "workflow.add_node(\"llm\", call_llm)\n",
    "\n",
    "# 메모리 저장\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# 스레드 ID 생성\n",
    "thread_id = uuid.uuid4()\n",
    "\n",
    "# 스레드 ID 지정\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "# 대화 시작\n",
    "query = \"안녕하세요. 저는 홍길동입니다.\"\n",
    "\n",
    "input_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"당신은 상점을 운영하는 상인입니다. \n",
    "        고객의 질문에 성실히 답하세요.\"\"\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": query},\n",
    "]\n",
    "for event in app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "# 새로운 대화\n",
    "new_query = \"제 이름을 기억하나요?\"\n",
    "new_input_messages = [\n",
    "    {\"role\": \"user\", \"content\": new_query},\n",
    "]\n",
    "\n",
    "for event in app.stream({\"messages\": new_input_messages}, config, stream_mode=\"values\"):\n",
    "    event[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf faiss-cpu --q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "page_content='While Link’s traditional green \n",
      "tunic is certainly an iconic look, his \n",
      "wardrobe has expanded quite a bit \n",
      "in his latest adventure. How you \n",
      "dress isn’t just an expression of \n",
      "personal style either. In addition \n",
      "to upping your defense a bit, \n",
      "different outﬁts have different \n",
      "effects that will prove useful \n",
      "depending on what you’re doing \n",
      "and where you’re going. The Warm \n",
      "Doublet, for example, is a fantastic \n",
      "fusion of fashion and function. It \n",
      "not only looks rather spiffy, it also \n",
      "protects you from the cold, allow-\n",
      "ing you to explore snowy areas \n",
      "without losing health along the \n",
      "way. The Climber’s set ups your \n",
      "climbing speed, which means \n",
      "you’ll be able to climb farther than \n",
      "you normally would \n",
      "before running out of \n",
      "stamina. The Stealth set \n",
      "increases your stealth, \n",
      "so it’s handy when \n",
      "you’re out hunting or \n",
      "trying to sneak up on \n",
      "enemies. The Zora \n",
      "Armor not only helps \n",
      "you swim faster, it also allows you \n",
      "to swim up waterfalls. Wearing a \n",
      "complete set with upgraded \n",
      "pieces can even provide a bonus \n",
      "effect. So if you plan on using an \n",
      "armor ability frequently, make it a \n",
      "point to ﬁnd all of the pieces in \n",
      "that set and upgrade them! In fact, \n",
      "given the variety of looks and \n",
      "affects out there, you’ll want to \n",
      "collect as many duds as you can \n",
      "and change them frequently to get \n",
      "the most out of your adventure. You \n",
      "can even dye your outﬁts to the \n",
      "color of your choice by taking the \n",
      "right ingredients and some rupees \n",
      "to the Kochi Dye Shop in Hateno \n",
      "Village, so don’t discount a useful \n",
      "bit of clothing because you’re not \n",
      "fond of the color! All that said, if \n",
      "you prefer to run around \n",
      "Hyrule in nothing but \n",
      "your skivvies...that’s a \n",
      "perfectly valid choice as \n",
      "well. Just don’t expect \n",
      "Hyrule’s residents to \n",
      "take too kindly to that \n",
      "decision.\n",
      "67 68\n",
      "Dress for Success' metadata={'source': 'files/ExplorersGuide.pdf', 'page': 35, 'page_label': '36'}\n",
      "링크의 전형적인 의상 색깔은 녹색입니다.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "load_env_from_project_root()\n",
    "\n",
    "# file_path = Path(__file__).parent.joinpath(\"files\").joinpath(\"ExplorersGuide.pdf\")\n",
    "file_path = \"files/ExplorersGuide.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "db = FAISS.from_documents(pages, embeddings)\n",
    "\n",
    "q = \"링크의 전형적인 의상 색깔은 무엇인가요?\"\n",
    "print(db.similarity_search(q)[0])\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "chain = RetrievalQA.from_llm(llm=llm, retriever=db.as_retriever())\n",
    "\n",
    "print(chain.invoke(q, return_only_outputs=True)['result'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라마인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-core in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (0.12.16.post1)\n",
      "Requirement already satisfied: llama-index-readers-file in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (0.4.4)\n",
      "Collecting llama-index-llms-ollama\n",
      "  Downloading llama_index_llms_ollama-0.5.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl.metadata (767 bytes)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (2025.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core) (1.17.2)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-readers-file) (4.13.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-readers-file) (2.2.3)\n",
      "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-readers-file) (5.2.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Collecting ollama>=0.4.3 (from llama-index-llms-ollama)\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.28.1)\n",
      "Collecting sentence-transformers>=2.6.1 (from llama-index-embeddings-huggingface)\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.18.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.17.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.2)\n",
      "Requirement already satisfied: click in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core) (2.3.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (4.48.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core) (3.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pandas->llama-index-readers-file) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-readers-file) (1.17.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.5.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.0.2)\n",
      "Downloading llama_index_llms_ollama-0.5.2-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.5.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Installing collected packages: ollama, llama-index-llms-ollama, sentence-transformers, llama-index-embeddings-huggingface\n",
      "Successfully installed llama-index-embeddings-huggingface-0.5.1 llama-index-llms-ollama-0.5.2 ollama-0.4.7 sentence-transformers-3.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-core llama-index-readers-file llama-index-llms-ollama llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "Link의 전형적인 의상 색깔은 녹색입니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "load_env_from_project_root()\n",
    "\n",
    "# 데이터 폴더의 문서를 로드 및 색인\n",
    "llm = OpenAI(model_name=\"gpt-4o-mini\")\n",
    "documents = SimpleDirectoryReader(\"files\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, llm=llm)\n",
    "\n",
    "# 쿼리 작성\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"링크의 전형적인 의상 색깔은 무엇인가요?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라마인덱스 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-faiss\n",
      "  Downloading llama_index_vector_stores_faiss-0.3.0-py3-none-any.whl.metadata (658 bytes)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-vector-stores-faiss) (0.12.16.post1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.0.38)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.11.12)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.8)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2025.2.0)\n",
      "Requirement already satisfied: httpx in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.4.2)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.10.6)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (9.0.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.18.3)\n",
      "Requirement already satisfied: click in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (3.26.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (24.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\campus3s043\\desktop\\alpaco_lectures\\venv\\lib\\site-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-faiss) (1.3.1)\n",
      "Downloading llama_index_vector_stores_faiss-0.3.0-py3-none-any.whl (3.9 kB)\n",
      "Installing collected packages: llama-index-vector-stores-faiss\n",
      "Successfully installed llama-index-vector-stores-faiss-0.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\venv\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:110: DeprecationWarning: Call to deprecated method get_doc_id. ('get_doc_id' is deprecated, access the 'id_' property instead.) -- Deprecated since version 0.12.2.\n",
      "  docstore.set_document_hash(doc.get_doc_id(), doc.hash)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "링크의 전형적인 의상 색깔은 녹색입니다.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_index.core import (SimpleDirectoryReader, StorageContext,\n",
    "                              VectorStoreIndex)\n",
    "from llama_index.core.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "\n",
    "load_env_from_project_root()\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "Settings.embed_model = OpenAIEmbedding()\n",
    "\n",
    "# FAISS 인덱스 생성 (1536은 OpenAI 임베딩 차원)\n",
    "dimension = 1536\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# FAISS 벡터 저장소 생성\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)\n",
    "\n",
    "# 임베딩을 위한 스토리지 세팅\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# 데이터 폴더 내의 문서를 로드 및 색인\n",
    "documents = SimpleDirectoryReader(\"files\").load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context)\n",
    "\n",
    "# 쿼리 작성\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"링크의 전형적인 의상 색깔은 무엇인가요?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어시스턴트 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "링크의 전형적인 의상 색깔은 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_env_from_project_root()\n",
    "client = OpenAI()\n",
    "\n",
    "def waiting_assistant_in_progress(thread_id, run_id, max_loops=20):\n",
    "    for _ in range(max_loops):\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run_id\n",
    "        )\n",
    "        if run.status != 'in_progress':\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return run\n",
    "\n",
    "# 파일 추가 완료 함수\n",
    "def waiting_file_batch_in_progress(file_batch, max_loops=20):\n",
    "    for _ in range(max_loops):\n",
    "        if file_batch.status != 'in_progress':\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    return file_batch\n",
    "\n",
    "# 벡터 저장소 \"Explorers Guide\" 생성\n",
    "vector_store = client.beta.vector_stores.create(name=\"Explorers Guide\")\n",
    " \n",
    "# PDF 파일 업로드\n",
    "file_streams = [open('files/ExplorersGuide.pdf', \"rb\")]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# 파일 업로드 완료 대기\n",
    "file_batch = waiting_file_batch_in_progress(file_batch)\n",
    "\n",
    "# 어시스턴트 생성\n",
    "zelda_expert_assistant = client.beta.assistants.create(\n",
    "    name='Zelda expert',\n",
    "    instructions='''당신은 비디오 게임 젤다의 전문가이며, 제가 드린 파일을 사용하여 게임에 대한 질문에 답해 주셔야 합니다.''',\n",
    "    model='gpt-4o',\n",
    "    tools=[{'type': 'file_search'}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
    ")\n",
    "\n",
    "\n",
    "# 스레드 생성\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 스레드에 메시지 추가\n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role='user',\n",
    "    content='링크의 전형적인 의상 색깔은 무엇인가요?'\n",
    ")\n",
    "\n",
    "# 스레드 실행\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=zelda_expert_assistant.id\n",
    ")\n",
    "\n",
    "# 스레드 실행 완료 후 결과 출력\n",
    "run = waiting_assistant_in_progress(thread.id, run.id)\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(messages.data[0].content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded .env from: c:\\Users\\campus3S043\\Desktop\\alpaco_lectures\\step10_LLM\\.env\n",
      "베를린의 현재 기온은 3°C입니다.\n"
     ]
    }
   ],
   "source": [
    "import time, json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_env_from_project_root()\n",
    "client = OpenAI()\n",
    "\n",
    "def waiting_assistant_in_progress(thread_id, run_id, max_loops=20):\n",
    "    for _ in range(max_loops):\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run_id\n",
    "        )\n",
    "        if (run.status == 'requires_action'\n",
    "            and run.required_action.type == 'submit_tool_outputs'):\n",
    "\n",
    "            tool_call = run.required_action.submit_tool_outputs.tool_calls[0]\n",
    "            if tool_call.function.name == 'getCurrentTemperature':\n",
    "                arguments = json.loads(tool_call.function.arguments)\n",
    "                fct_output = getCurrentTemperature(arguments['city'])\n",
    "            else:\n",
    "                raise Exception('Unexpected function')\n",
    "\n",
    "            client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=[\n",
    "                    {\n",
    "                        'tool_call_id': tool_call.id,\n",
    "                        'output': fct_output\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        time.sleep(1)\n",
    "    return run\n",
    "\n",
    "\n",
    "\n",
    "def getCurrentTemperature(city):\n",
    "    return str(len(city)) + '°C'\n",
    "\n",
    "function = {\n",
    "    'name': 'getCurrentTemperature',\n",
    "    'description': '도시의 현재 기온을 가져오는 함수',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'city': {\n",
    "                'type': 'string',\n",
    "                'description':\n",
    "                '기온을 가져올 도시의 이름.'\n",
    "                '예: ‘뉴욕’, ‘런던’, 등'\n",
    "            }\n",
    "        },\n",
    "        'required': ['city']\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [{\n",
    "    'type': 'function',\n",
    "            'function': function\n",
    "}]\n",
    "\n",
    "client = OpenAI()\n",
    "assistant = client.beta.assistants.create(\n",
    "    name='Weather Assistant',\n",
    "    instructions='당신은 외부 도구를 사용하여 도시의 현재 기온을 제공하는 어시스턴트입니다.',\n",
    "    model='gpt-4o-mini',\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role='user',\n",
    "    content='베를린의 현재 기온은 얼마인가요?'\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "run = waiting_assistant_in_progress(thread.id, run.id)\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(messages.data[0].content[0].text.value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
