##### ê¸°ë³¸ ì •ë³´ ì…ë ¥ ####
# Streamlit íŒ¨í‚¤ì§€ ì¶”ê°€
import streamlit as st

# OpenAI íŒ¨í‚¤ì§€ ì¶”ê°€
from openai import OpenAI

# ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ íŒŒì´ì¬ ê¸°ë³¸ íŒ¨í‚¤ì§€
import os
import io
import base64
from PIL import Image
from get_key import get_openai_key

OPENAI_API_KEY = get_openai_key()

# GPT-4Vì™€ TTSë¥¼ ìœ„í•œ client ì„ ì–¸
client = OpenAI(
    api_key = OPENAI_API_KEY
)

#### ê¸°ëŠ¥ êµ¬í˜„ í•¨ìˆ˜ ì •ë¦¬ ####
# GPT-4V
def describe(text):
    response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {
        "role": "user",
        "content": [
            {"type": "text", "text": "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ ì•„ì£¼ ìì„¸íˆ ë¬˜ì‚¬í•´ì¤˜"},
            {
            "type": "image_url",
            "image_url": {
                "url": text,
            },
            },
        ],
        }
    ],
    max_tokens=1024,
    )
    return response.choices[0].message.content

# TTS
def TTS(response):    
    # TTSë¥¼ í™œìš©í•˜ì—¬ ë§Œë“  ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥.
    response = client.audio.speech.create(
    model="tts-1",
    voice="onyx",
    input=response
    )
    filename = "output.mp3"
    response.stream_to_file(filename)

    # ì €ì¥í•œ ìŒì„± íŒŒì¼ ìë™ ì¬ìƒ
    with open(filename, "rb") as f:
        data = f.read()
        b64 = base64.b64encode(data).decode()
        # HTML ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ìŒì›ì„ ì¬ìƒí•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬
        # streamlit ì•ˆì—ì„œ HTML ë¬¸ë²• êµ¬í˜„ì— ì‚¬ìš©ë˜ëŠ” st.markdown() ì„ í™œìš©í•˜ì—¬ ì‹¤í–‰ì„ í•©ë‹ˆë‹¤.
        md = f"""
            <audio autoplay="True">
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
            </audio>
            """
        st.markdown(md, unsafe_allow_html=True,)
    # í´ë”ì— ë‚¨ì§€ ì•Šë„ë¡ íŒŒì¼ ì‚­ì œ
    os.remove(filename)

##### ë©”ì¸ í•¨ìˆ˜ #####
def main():
    st.image('ai.png', width=200)
    st.title("ğŸ’¬ ì´ë¯¸ì§€ë¥¼ í•´ì„¤í•´ë“œë¦½ë‹ˆë‹¤.")

    # ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œ
    img_file_buffer = st.file_uploader('Upload a PNG image', type='png')

    if img_file_buffer is not None:
        image = Image.open(img_file_buffer)

        # ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ í™”ë©´ì— ì¶œë ¥
        st.image(image, caption='Uploaded Image.', use_column_width=True)

        # ì´ë¯¸ì§€ => ë°”ì´íŠ¸ ë²„í¼ë¡œ ë³€í™˜
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        
        # ë°”ì´íŠ¸ ë²„í¼ => Base64 ì¸ì½”ë”© ë°”ì´íŠ¸ ë¬¸ìì—´ë¡œ ë³€í™˜
        img_base64 = base64.b64encode(buffered.getvalue())
        
        # Base64 ì¸ì½”ë”© ë°”ì´íŠ¸ ë¬¸ìì—´ => UTF-8 ë¬¸ìì—´ë¡œ ë””ì½”ë”©
        img_base64_str = img_base64.decode('utf-8')

        # GPT-4Vì—ì„œ ì…ë ¥ë°›ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜
        # ì˜ˆì‹œ ì°¸ê³ : https://platform.openai.com/docs/guides/vision/uploading-base-64-encoded-images
        image = f"data:image/jpeg;base64,{img_base64_str}"

        # GPT4Vê°€ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ë°˜í™˜í•˜ê³  ì´ë¥¼ st.info()ë¡œ ì¶œë ¥.
        text = describe(image)
        st.info(text)

        # ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ ìŒì„±ìœ¼ë¡œ ë³€í™˜.
        TTS(text)

if __name__=="__main__":
    main()
