{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84493,"databundleVersionId":9871156,"sourceType":"competition"},{"sourceId":217587,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":185551,"modelId":207681}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:26.322894Z","iopub.execute_input":"2025-01-10T03:31:26.323219Z","iopub.status.idle":"2025-01-10T03:31:26.662431Z","shell.execute_reply.started":"2025-01-10T03:31:26.323192Z","shell.execute_reply":"2025-01-10T03:31:26.661607Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jane-street-real-time-market-data-forecasting/responders.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/sample_submission.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/features.csv\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=4/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=5/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=6/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=3/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=1/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=8/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=2/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=7/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=9/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet/date_id=0/part-0.parquet\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/jane_street_inference_server.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/templates.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/relay.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/__init__.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/jane-street-real-time-market-data-forecasting/kaggle_evaluation/core/generated/__init__.py\n/kaggle/input/preprocessed_data_mini/tensorflow2/default/1/validation_data.parquet\n/kaggle/input/preprocessed_data_mini/tensorflow2/default/1/training_data.parquet\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport polars as pl\nimport gc\n\ntest_df = pl.scan_parquet(\n    f\"/kaggle/input/preprocessed_data_mini/tensorflow2/default/1/training_data.parquet\"\n).collect().to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:28.571556Z","iopub.execute_input":"2025-01-10T03:31:28.571981Z","iopub.status.idle":"2025-01-10T03:31:43.405177Z","shell.execute_reply.started":"2025-01-10T03:31:28.571953Z","shell.execute_reply":"2025-01-10T03:31:43.404256Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"val_df = pl.scan_parquet(\n    f\"/kaggle/input/preprocessed_data_mini/tensorflow2/default/1/validation_data.parquet\"\n).collect().to_pandas()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:43.406453Z","iopub.execute_input":"2025-01-10T03:31:43.406723Z","iopub.status.idle":"2025-01-10T03:31:44.014218Z","shell.execute_reply.started":"2025-01-10T03:31:43.406699Z","shell.execute_reply":"2025-01-10T03:31:44.013526Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# 데이터 처리","metadata":{}},{"cell_type":"code","source":"# 데이터 LSTM 입력화\n\ndef dat_to_input(data):\n    features = data.filter(regex='^feature_')\n    responders = data.filter(regex='^responder_')\n    weights = data['weight']\n\n    gc.collect()\n\n    # Convert to numpy arrays for TensorFlow\n    X = features.values  # Features for input\n\n    # Assuming you have a DataFrame `y_train` with all responders <- noooo\n    y = responders[['responder_6']].values  # Keep only responder_6\n\n    # run if nan or inf exists - \n    #X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n    #y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)\n\n    return X,y\n\n\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:44.015486Z","iopub.execute_input":"2025-01-10T03:31:44.015736Z","iopub.status.idle":"2025-01-10T03:31:44.065830Z","shell.execute_reply.started":"2025-01-10T03:31:44.015701Z","shell.execute_reply":"2025-01-10T03:31:44.064918Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"X, y = dat_to_input(test_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:44.067097Z","iopub.execute_input":"2025-01-10T03:31:44.067344Z","iopub.status.idle":"2025-01-10T03:31:46.789455Z","shell.execute_reply.started":"2025-01-10T03:31:44.067324Z","shell.execute_reply":"2025-01-10T03:31:46.788723Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X_val, y_val = dat_to_input(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:46.790302Z","iopub.execute_input":"2025-01-10T03:31:46.790542Z","iopub.status.idle":"2025-01-10T03:31:46.976953Z","shell.execute_reply.started":"2025-01-10T03:31:46.790521Z","shell.execute_reply":"2025-01-10T03:31:46.976039Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:46.977796Z","iopub.execute_input":"2025-01-10T03:31:46.978030Z","iopub.status.idle":"2025-01-10T03:31:46.982643Z","shell.execute_reply.started":"2025-01-10T03:31:46.978010Z","shell.execute_reply":"2025-01-10T03:31:46.981979Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(8649459, 79)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"X = X.reshape(-1, 3, 79)\nX_val = X_val.reshape(-1,1,79)\n\nprint(X.shape, X_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:46.983363Z","iopub.execute_input":"2025-01-10T03:31:46.983603Z","iopub.status.idle":"2025-01-10T03:31:46.997233Z","shell.execute_reply.started":"2025-01-10T03:31:46.983583Z","shell.execute_reply":"2025-01-10T03:31:46.996403Z"}},"outputs":[{"name":"stdout","text":"(2883153, 3, 79) (452056, 1, 79)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:46.999052Z","iopub.execute_input":"2025-01-10T03:31:46.999278Z","iopub.status.idle":"2025-01-10T03:31:47.059679Z","shell.execute_reply.started":"2025-01-10T03:31:46.999260Z","shell.execute_reply":"2025-01-10T03:31:47.058928Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# AutoEncoder","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Dense, LSTM, GRU, Input, TimeDistributed, Reshape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:47.060576Z","iopub.execute_input":"2025-01-10T03:31:47.060836Z","iopub.status.idle":"2025-01-10T03:31:54.479051Z","shell.execute_reply.started":"2025-01-10T03:31:47.060809Z","shell.execute_reply":"2025-01-10T03:31:54.478362Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, Reshape\nfrom keras.losses import Huber\nfrom keras.optimizers import Adam\n\n# 입력 레이어\ninput_layer = Input(shape=(X.shape[1], X.shape[2]))  # (타임스텝, 특성)\n\n# 인코더: 다층 LSTM\nencoded = LSTM(128, activation='relu', return_sequences=True)(input_layer)  # 첫 번째 LSTM\nencoded = Dropout(0.2)(encoded)  # Dropout으로 과적합 방지\nencoded = LSTM(64, activation='relu', return_sequences=False)(encoded)  # 두 번째 LSTM\nencoded = BatchNormalization()(encoded)  # BatchNormalization으로 학습 안정화\n\n# Bottleneck\nbottleneck = Dense(64, activation='relu')(encoded)  # 잠재 공간\nbottleneck = Dropout(0.2)(bottleneck)  # Dropout 추가\n\n# 디코더: Dense -> LSTM\ndecoded = Dense(X.shape[1] * X.shape[2], activation='relu')(bottleneck)  # Latent 공간을 펼치기\ndecoded = Reshape((X.shape[1], X.shape[2]))(decoded)  # 원래 시계열 차원으로 복원\ndecoded = LSTM(64, activation='relu', return_sequences=True)(decoded)  # LSTM으로 시계열 복원\ndecoded = Dropout(0.2)(decoded)\ndecoded = LSTM(X.shape[2], activation='relu', return_sequences=True)(decoded)\n\n# Autoencoder 모델\nautoencoder = Model(inputs=input_layer, outputs=decoded)\nautoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=Huber(delta=1.0))  # Huber Loss 적용\nautoencoder.summary()\n\n# 학습\nautoencoder.fit(X, X, epochs=5, batch_size=64, validation_split=0.2, verbose=1)  # Epoch 조정 가능\n\n# 인코더 모델\nencoder = Model(inputs=input_layer, outputs=bottleneck)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:31:54.479794Z","iopub.execute_input":"2025-01-10T03:31:54.480252Z","iopub.status.idle":"2025-01-10T03:43:59.437806Z","shell.execute_reply.started":"2025-01-10T03:31:54.480230Z","shell.execute_reply":"2025-01-10T03:43:59.437089Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m79\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m106,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m237\u001b[0m)                 │          \u001b[38;5;34m15,405\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m79\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │          \u001b[38;5;34m36,864\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m79\u001b[0m)               │          \u001b[38;5;34m45,504\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">106,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">237</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,405</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">79</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">45,504</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m258,093\u001b[0m (1008.18 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">258,093</span> (1008.18 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m257,965\u001b[0m (1007.68 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">257,965</span> (1007.68 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 4ms/step - loss: 0.3276 - val_loss: 0.2341\nEpoch 2/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 4ms/step - loss: 0.2884 - val_loss: 0.2291\nEpoch 3/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - loss: 0.2791 - val_loss: 0.2275\nEpoch 4/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 4ms/step - loss: 0.2750 - val_loss: 0.2283\nEpoch 5/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 4ms/step - loss: 0.2724 - val_loss: 0.2280\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.438588Z","iopub.execute_input":"2025-01-10T03:43:59.438827Z","iopub.status.idle":"2025-01-10T03:43:59.659514Z","shell.execute_reply.started":"2025-01-10T03:43:59.438806Z","shell.execute_reply":"2025-01-10T03:43:59.658715Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"752"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"'''\n# Autoencoder 모델 구축\ninput_layer = Input(shape=(X.shape[1], X.shape[2]))  # (타임스텝, 특성)\nencoded = LSTM(128, activation='relu', return_sequences=False)(input_layer)  # 인코더\n\nbottleneck = Dense(64, activation='relu')(encoded)  # 반환점 - bottleneck\n\n# 디코더: Latent 공간 -> 원래 시계열 차원 복원\ndecoded = Dense(X.shape[1] * X.shape[2], activation='relu')(bottleneck)  # 전체 차원 펼치기\ndecoded = Reshape((X.shape[1], X.shape[2]))(decoded)  # (타임스텝, 특성)으로 복원\n\nautoencoder = Model(inputs=input_layer, outputs=decoded)\nautoencoder.compile(optimizer='adam', loss='mse')\nautoencoder.summary()\n\n# Autoencoder 학습\nautoencoder.fit(X, X, epochs=5, batch_size=32, validation_split=0.2, verbose=1) # 여기를 조정해서 학습 시간 단축 가능 - 현재 20분 정도\n\n# Encoder 모델 구축\nencoder = Model(inputs=input_layer, outputs=bottleneck)\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.660262Z","iopub.execute_input":"2025-01-10T03:43:59.660481Z","iopub.status.idle":"2025-01-10T03:43:59.674499Z","shell.execute_reply.started":"2025-01-10T03:43:59.660461Z","shell.execute_reply":"2025-01-10T03:43:59.673702Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\"\\n# Autoencoder 모델 구축\\ninput_layer = Input(shape=(X.shape[1], X.shape[2]))  # (타임스텝, 특성)\\nencoded = LSTM(128, activation='relu', return_sequences=False)(input_layer)  # 인코더\\n\\nbottleneck = Dense(64, activation='relu')(encoded)  # 반환점 - bottleneck\\n\\n# 디코더: Latent 공간 -> 원래 시계열 차원 복원\\ndecoded = Dense(X.shape[1] * X.shape[2], activation='relu')(bottleneck)  # 전체 차원 펼치기\\ndecoded = Reshape((X.shape[1], X.shape[2]))(decoded)  # (타임스텝, 특성)으로 복원\\n\\nautoencoder = Model(inputs=input_layer, outputs=decoded)\\nautoencoder.compile(optimizer='adam', loss='mse')\\nautoencoder.summary()\\n\\n# Autoencoder 학습\\nautoencoder.fit(X, X, epochs=5, batch_size=32, validation_split=0.2, verbose=1) # 여기를 조정해서 학습 시간 단축 가능 - 현재 20분 정도\\n\\n# Encoder 모델 구축\\nencoder = Model(inputs=input_layer, outputs=bottleneck)\\n\""},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"'''\n# 3. GRU 모델 구축\n# Autoencoder를 통해 Latent Representation 추출\nlatent_train = encoder.predict(X)\nlatent_test = encoder.predict(X_val)\n\n# GRU를 활용한 예측\ngru_model = Sequential([\n    GRU(128, activation='relu', input_shape=(1, latent_train.shape[1]), return_sequences=False),\n    Dense(64, activation='relu'),\n    Dense(y.shape[1], activation='linear')  # 다중 특성 예측\n])\n\ngru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\ngru_model.summary()\n\n# GRU 입력 차원 맞추기\nlatent_train = latent_train.reshape(latent_train.shape[0], 1, latent_train.shape[1])\nlatent_test = latent_test.reshape(latent_test.shape[0], 1, latent_test.shape[1])\n\n# GRU 학습\ngru_model.fit(latent_train, y, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\n\n# GRU 예측\npredictions = gru_model.predict(latent_test) # 다 같은 답을 내놓는다. 뭔가 문제가 있음. \n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.675271Z","iopub.execute_input":"2025-01-10T03:43:59.675552Z","iopub.status.idle":"2025-01-10T03:43:59.694541Z","shell.execute_reply.started":"2025-01-10T03:43:59.675522Z","shell.execute_reply":"2025-01-10T03:43:59.693750Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"\"\\n# 3. GRU 모델 구축\\n# Autoencoder를 통해 Latent Representation 추출\\nlatent_train = encoder.predict(X)\\nlatent_test = encoder.predict(X_val)\\n\\n# GRU를 활용한 예측\\ngru_model = Sequential([\\n    GRU(128, activation='relu', input_shape=(1, latent_train.shape[1]), return_sequences=False),\\n    Dense(64, activation='relu'),\\n    Dense(y.shape[1], activation='linear')  # 다중 특성 예측\\n])\\n\\ngru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\\ngru_model.summary()\\n\\n# GRU 입력 차원 맞추기\\nlatent_train = latent_train.reshape(latent_train.shape[0], 1, latent_train.shape[1])\\nlatent_test = latent_test.reshape(latent_test.shape[0], 1, latent_test.shape[1])\\n\\n# GRU 학습\\ngru_model.fit(latent_train, y, epochs=5, batch_size=32, validation_split=0.2, verbose=1)\\n\\n# GRU 예측\\npredictions = gru_model.predict(latent_test) # 다 같은 답을 내놓는다. 뭔가 문제가 있음. \\n\""},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"'''\nlatent_train = encoder.predict(X)\n\n# 1. GRU 모델 정의 및 학습\n# latent_train은 훈련 데이터의 특성 벡터, y_train은 목표 변수입니다.\ngru_model = Sequential([\n    GRU(128, activation='relu', input_shape=(1, latent_train.shape[1]), return_sequences=False),\n    Dense(64, activation='relu'),\n    Dense(latent_train.shape[1], activation='linear')  # y_train의 특성 수에 맞게\n])\n\ngru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\ngru_model.summary()\n'''\n# 아래 모델로 대체 가능? 아래 모델도 층이 그다지 깊어 보이지는 않는다...","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.695382Z","iopub.execute_input":"2025-01-10T03:43:59.695703Z","iopub.status.idle":"2025-01-10T03:43:59.709410Z","shell.execute_reply.started":"2025-01-10T03:43:59.695665Z","shell.execute_reply":"2025-01-10T03:43:59.708720Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"\\nlatent_train = encoder.predict(X)\\n\\n# 1. GRU 모델 정의 및 학습\\n# latent_train은 훈련 데이터의 특성 벡터, y_train은 목표 변수입니다.\\ngru_model = Sequential([\\n    GRU(128, activation='relu', input_shape=(1, latent_train.shape[1]), return_sequences=False),\\n    Dense(64, activation='relu'),\\n    Dense(latent_train.shape[1], activation='linear')  # y_train의 특성 수에 맞게\\n])\\n\\ngru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\\ngru_model.summary()\\n\""},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"import tensorflow as tf\n\ndef r_squared(y_true, y_pred):\n    \"\"\"\n    R-squared 계산 함수\n    y_true: 실제 값\n    y_pred: 예측 값\n    \"\"\"\n    # Residual sum of squares\n    ss_res = tf.reduce_sum(tf.square(y_true - y_pred))\n    \n    # Total sum of squares\n    ss_tot = tf.reduce_sum(tf.square(y_true - tf.reduce_mean(y_true)))\n    \n    # R-squared 계산\n    r2 = 1 - ss_res / (ss_tot + tf.keras.backend.epsilon())  # epsilon으로 0 나눔 방지\n    \n    return r2  # 반환값이 Tensor여야 함 - Tensor 함수 특징? ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.710209Z","iopub.execute_input":"2025-01-10T03:43:59.710539Z","iopub.status.idle":"2025-01-10T03:43:59.726328Z","shell.execute_reply.started":"2025-01-10T03:43:59.710508Z","shell.execute_reply":"2025-01-10T03:43:59.725600Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import GRU, Dense, Dropout, BatchNormalization\nfrom keras.callbacks import EarlyStopping\n\n# X 훈련 데이터 학습시키기 \nlatent_train = encoder.predict(X)\n\n# 1. GRU 모델 정의\ngru_model = Sequential([\n    # 첫 번째 GRU 레이어: 더 많은 유닛 추가 및 정규화 적용\n    GRU(256, activation='tanh', input_shape=(1, latent_train.shape[1]), return_sequences=True),\n    BatchNormalization(),\n    Dropout(0.2),  # 과적합 방지를 위한 드롭아웃\n\n    # 두 번째 GRU 레이어: 추가 유닛 및 정규화\n    GRU(128, activation='tanh', return_sequences=False),\n    BatchNormalization(),\n    Dropout(0.2),\n\n    # 첫 번째 Dense 레이어: 더 많은 노드 추가 및 활성화 함수 사용\n    Dense(128, activation='relu'), # 여기서 Relu를 통해 음수를 0으로 만든다. \n    BatchNormalization(),\n\n    # 출력 레이어: y_train의 특성 수에 맞는 선형 활성화 함수 사용\n    Dense(latent_train.shape[1], activation='linear')\n])\n\n# Early Stopping 추가\nearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n\n# 2. 컴파일 단계\ngru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n\n# 3. 모델 구조 요약\ngru_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:43:59.727094Z","iopub.execute_input":"2025-01-10T03:43:59.727347Z","iopub.status.idle":"2025-01-10T03:47:14.652858Z","shell.execute_reply.started":"2025-01-10T03:43:59.727315Z","shell.execute_reply":"2025-01-10T03:47:14.652189Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m90099/90099\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 1ms/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │         \u001b[38;5;34m247,296\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m148,224\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">247,296</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">148,224</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m422,336\u001b[0m (1.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">422,336</span> (1.61 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m421,312\u001b[0m (1.61 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">421,312</span> (1.61 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n</pre>\n"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:47:14.653586Z","iopub.execute_input":"2025-01-10T03:47:14.653811Z","iopub.status.idle":"2025-01-10T03:47:14.866796Z","shell.execute_reply.started":"2025-01-10T03:47:14.653778Z","shell.execute_reply":"2025-01-10T03:47:14.865879Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"358"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"# GRU 모델 훈련\n# latent_train을 3D 배열로 변환 (배치 크기, 타임스텝, 특성)\nlatent_train_reshaped = latent_train.reshape(latent_train.shape[0]//1, 1, latent_train.shape[1]) # Timestep을 3개에서 1개로 변경함. 필요하다면 다시 1 대신 다른 숫자로 변경이 가능함. \n\ngru_model_trained = gru_model.fit(latent_train_reshaped ,y ,epochs=5, batch_size=64, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n\n# latent_train_reshaped가 훈련 데이터, y가 출력 데이터를 의미한다. 즉, y는 responder_6, latent_test는 이코더에 y를 던져 넣은 것.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-10T03:47:23.858626Z","iopub.execute_input":"2025-01-10T03:47:23.858931Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 8ms/step - loss: 0.8980 - mae: 0.6321 - val_loss: 0.5985 - val_mae: 0.4961\nEpoch 2/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 8ms/step - loss: 0.8870 - mae: 0.6255 - val_loss: 0.5986 - val_mae: 0.4963\nEpoch 3/5\n\u001b[1m36040/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 8ms/step - loss: 0.8876 - mae: 0.6258 - val_loss: 0.5995 - val_mae: 0.4980\nEpoch 4/5\n\u001b[1m31720/36040\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - loss: 0.8824 - mae: 0.6244","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"gru_model_trained.history\n\n# 모델 개선 방안 강구 ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-10T03:29:27.132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 안 해도 되나?\n'''\n# 2. 미래 39단위 예측\nn_steps = 39 #(예측할 단위)\n\n# 첫 번째 입력을 latent_train에서 가져옵니다. (예: 첫 번째 샘플)\ninput_sequence = latent_train[0].reshape(1, 1, latent_train.shape[1])  # (1, 1, latent_train.shape[1])로 변환\n\n# 예측 결과를 저장할 리스트\nfuture_predictions = []\n\n# 예측을 39번 반복해서 진행\nfor i in range(n_steps):\n    # GRU 모델로 예측\n    pred = gru_model.predict(input_sequence)\n    \n    # 예측된 값을 결과에 추가\n    future_predictions.append(pred[0])  # pred[0]은 예측된 타겟 벡터 (배치 크기가 1이라서)\n\n    # 예측된 값을 다시 input_sequence에 추가하여 다음 예측에 사용\n    input_sequence = np.append(input_sequence[:, 1:, :], pred.reshape(1, 1, latent_train.shape[1]), axis=1)\n\n# 결과를 numpy 배열로 변환\nfuture_predictions = np.array(future_predictions)\n'''","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-10T03:29:27.132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''\n# 예측 결과를 데이터프레임 형태로 변환 (원본 y와 같은 형태로 출력)\npredicted_df = pd.DataFrame(future_predictions, columns=[f\"target_{i+1}\" for i in range(future_predictions.shape[1])])\n\n# 예측 결과 출력\nprint(predicted_df)\n'''","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-10T03:29:27.132Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 개선 방안 강구\n현 상황: 데이터가 제대로 학습하지 못하고 있음.\n- latent 및 y를 정규화한다\n- Adam의 학습률을 낮추거나 증가시킨다\n- 노드 추가 혹은 감소\n- 드롭아웃 추가","metadata":{}},{"cell_type":"markdown","source":"# RES Submit - 여기가 문제다!","metadata":{}},{"cell_type":"code","source":"# Submit ERROR?? - CFG\n\nlags_ : pl.DataFrame | None = None\n\n\n# Replace this function with your inference code.\n# You can return either a Pandas or Polars dataframe, though Polars is recommended.\n# Each batch of predictions (except the very first) must be returned within 10 minutes of the batch features being provided.\ndef predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n    \"\"\"Make a prediction.\"\"\"\n    # All the responders from the previous day are passed in at time_id == 0. We save them in a global variable for access at every time_id.\n    # Use them as extra features, if you like.\n    global lags_\n    if lags is not None:\n        lags_ = lags\n    # 1. Select the required feature columns and convert to numpy array for Keras\n    X_test = test.select(CFG.feature_columns).to_numpy()\n    X_test = np.where(np.isnan(X_test), mean_values, X_test)\n    X_test = (X_test - min_values) / max_min_diff\n    # 2. Make predictions using the Keras model\n    y_pred = gru_model_trained.predict(X_test, batch_size=4096)\n    \n    # 3. Prepare the DataFrame for output\n    predictions = test.select('row_id').with_columns(\n        pl.Series(\"responder_6\", y_pred.flatten())\n    )\n    # The predict function must return a DataFrame\n    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n    # with columns 'row_id', 'responer_6'\n    assert predictions.columns == ['row_id', 'responder_6']\n    # and as many rows as the test data.\n    assert len(predictions) == len(test)\n\n    return predictions","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-10T03:29:27.132Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport kaggle_evaluation.jane_street_inference_server\n\ninference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\nif os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n    inference_server.serve()\nelse:\n    inference_server.run_local_gateway(\n        (\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n        )\n    )","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-10T03:29:27.132Z"}},"outputs":[],"execution_count":null}]}